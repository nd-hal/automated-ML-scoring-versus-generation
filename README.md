Dataset and code for interplay between human and GPT-generated text and ML models used to score them.

Includes:

1) Prompt Data: Prompt genres/types, prompt text, human responses, GPT-3.5 and GPT-4 responses
2) Statistical Analysis Data: ML model scores for assessing the different types of human/GPT text, and R script for ANOVA models 

If you use this repository please cite the accompanying paper:

@misc{bevilacqua2023automated,
      title={When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs}, 
      author={Marialena Bevilacqua and Kezia Oketch and Ruiyang Qin and Will Stamey and Xinyuan Zhang and Yi Gan and Kai Yang and Ahmed Abbasi},
      year={2023},
      eprint={2309.14488},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
